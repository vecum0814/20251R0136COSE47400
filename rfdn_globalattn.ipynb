{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "835fc0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Errno 2] No such file or directory: 'EDSR-PyTorch/'\n",
      "/home/elicer/EDSR-PyTorch/src\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/IPython/core/magics/osm.py:393: UserWarning: using bookmarks requires you to install the `pickleshare` library.\n",
      "  bkms = self.shell.db.get('bookmarks', {})\n"
     ]
    }
   ],
   "source": [
    "%cd EDSR-PyTorch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e5ddc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content        demo.py\t    loss     option.py\t  trainer.py\t  wandb\r\n",
      "data\t       demo.sh\t    main.py  __pycache__  utility.py\r\n",
      "dataloader.py  __init__.py  model    template.py  videotester.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92064157",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/EDSR-PyTorch/src\n"
     ]
    }
   ],
   "source": [
    "%cd src/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1854294f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content        demo.py\t    loss     option.py\t  trainer.py\t  wandb\r\n",
      "data\t       demo.sh\t    main.py  __pycache__  utility.py\r\n",
      "dataloader.py  __init__.py  model    template.py  videotester.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "828f0d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250525_094603-vxgcdzns\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/vxgcdzns\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10:   9%|‚ñà‚ñå               | 9/100 [00:15<01:53,  1.25s/it, Loss=94.4365]^C\n",
      "Epoch 1/10:   9%|‚ñà‚ñå               | 9/100 [00:16<02:48,  1.85s/it, Loss=94.4365]\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/main.py\", line 33, in <module>\n",
      "    main()\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/main.py\", line 27, in main\n",
      "    t.train()\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/trainer.py\", line 47, in train\n",
      "    for batch, (lr, hr, _,) in enumerate(pbar):\n",
      "  File \"/home/elicer/.local/lib/python3.10/site-packages/tqdm/std.py\", line 1181, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 633, in __next__\n",
      "    data = self._next_data()\n",
      "  File \"/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1328, in _next_data\n",
      "    idx, data = self._get_data()\n",
      "  File \"/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1284, in _get_data\n",
      "    success, data = self._try_get_data()\n",
      "  File \"/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py\", line 1132, in _try_get_data\n",
      "    data = self._data_queue.get(timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.10/queue.py\", line 180, in get\n",
      "    self.not_empty.wait(remaining)\n",
      "  File \"/usr/local/lib/python3.10/threading.py\", line 324, in wait\n",
      "    gotit = waiter.acquire(True, timeout)\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_GlobalAttn \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_x4_custom \\\n",
    "    --ext sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "754c8976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\r\n",
      "  warnings.warn(_create_warning_msg(\r\n",
      "Traceback (most recent call last):\r\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/main.py\", line 33, in <module>\r\n",
      "    main()\r\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/main.py\", line 22, in main\r\n",
      "    loader = data.Data(args)\r\n",
      "  File \"/home/elicer/EDSR-PyTorch/src/data/__init__.py\", line 45, in __init__\r\n",
      "    testset = DIV2KCustom(args, name=d, train=False, benchmark=False, n_channels=3)\r\n",
      "TypeError: DIV2KCustom.__init__() got an unexpected keyword argument 'n_channels'\r\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_GlobalAttn \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --chop \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33fc26b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting timm\n",
      "  Downloading timm-1.0.15-py3-none-any.whl.metadata (52 kB)\n",
      "Requirement already satisfied: torch in /home/elicer/.local/lib/python3.10/site-packages (from timm) (2.0.1)\n",
      "Requirement already satisfied: torchvision in /home/elicer/.local/lib/python3.10/site-packages (from timm) (0.15.2)\n",
      "Requirement already satisfied: pyyaml in /home/elicer/.local/lib/python3.10/site-packages (from timm) (6.0.2)\n",
      "Requirement already satisfied: huggingface_hub in /home/elicer/.local/lib/python3.10/site-packages (from timm) (0.31.4)\n",
      "Requirement already satisfied: safetensors in /home/elicer/.local/lib/python3.10/site-packages (from timm) (0.5.3)\n",
      "Requirement already satisfied: filelock in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (2025.3.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (23.2)\n",
      "Requirement already satisfied: requests in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/elicer/.local/lib/python3.10/site-packages (from huggingface_hub->timm) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/elicer/.local/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/elicer/.local/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/elicer/.local/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/elicer/.local/lib/python3.10/site-packages (from requests->huggingface_hub->timm) (2025.4.26)\n",
      "Requirement already satisfied: sympy in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (1.14.0)\n",
      "Requirement already satisfied: networkx in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu11==11.7.99 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu11==11.7.99 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.7.99)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu11==11.7.101 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.7.101)\n",
      "Requirement already satisfied: nvidia-cudnn-cu11==8.5.0.96 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (8.5.0.96)\n",
      "Requirement already satisfied: nvidia-cublas-cu11==11.10.3.66 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.10.3.66)\n",
      "Requirement already satisfied: nvidia-cufft-cu11==10.9.0.58 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (10.9.0.58)\n",
      "Requirement already satisfied: nvidia-curand-cu11==10.2.10.91 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (10.2.10.91)\n",
      "Requirement already satisfied: nvidia-cusolver-cu11==11.4.0.1 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.4.0.1)\n",
      "Requirement already satisfied: nvidia-cusparse-cu11==11.7.4.91 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.7.4.91)\n",
      "Requirement already satisfied: nvidia-nccl-cu11==2.14.3 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (2.14.3)\n",
      "Requirement already satisfied: nvidia-nvtx-cu11==11.7.91 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (11.7.91)\n",
      "Requirement already satisfied: triton==2.0.0 in /home/elicer/.local/lib/python3.10/site-packages (from torch->timm) (2.0.0)\n",
      "Requirement already satisfied: setuptools in /home/elicer/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->timm) (80.3.1)\n",
      "Requirement already satisfied: wheel in /home/elicer/.local/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch->timm) (0.45.1)\n",
      "Requirement already satisfied: cmake in /home/elicer/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->timm) (4.0.2)\n",
      "Requirement already satisfied: lit in /home/elicer/.local/lib/python3.10/site-packages (from triton==2.0.0->torch->timm) (18.1.8)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/elicer/.local/lib/python3.10/site-packages (from jinja2->torch->timm) (3.0.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /home/elicer/.local/lib/python3.10/site-packages (from sympy->torch->timm) (1.3.0)\n",
      "Requirement already satisfied: numpy in /home/elicer/.local/lib/python3.10/site-packages (from torchvision->timm) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /home/elicer/.local/lib/python3.10/site-packages (from torchvision->timm) (11.2.1)\n",
      "Downloading timm-1.0.15-py3-none-any.whl (2.4 MB)\n",
      "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m22.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: timm\n",
      "Successfully installed timm-1.0.15\n"
     ]
    }
   ],
   "source": [
    "!pip install timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35746b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250525_135616-8x9jn0n8\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/8x9jn0n8\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 14.60it/s, Loss=18.8572]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:35<00:00,  5.64it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.198\n",
      "Forward: 35.46s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.74it/s, Loss=16.5700]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.543\n",
      "Forward: 34.69s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.24it/s, Loss=10.8461]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.75it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.327\n",
      "Forward: 34.76s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.89it/s, Loss=7.0662]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.78it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.525\n",
      "Forward: 34.58s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.36it/s, Loss=11.9047]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.78it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.242\n",
      "Forward: 34.58s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.03it/s, Loss=10.4851]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.79it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.816\n",
      "Forward: 34.53s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.00it/s, Loss=11.5058]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.76it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.761\n",
      "Forward: 34.70s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.62it/s, Loss=8.6039]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.78it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.985\n",
      "Forward: 34.59s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.47it/s, Loss=12.8324]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:34<00:00,  5.79it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.073\n",
      "Forward: 34.57s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/8x9jn0n8\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250525_135616-8x9jn0n8/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_x4_custom \\\n",
    "    --ext sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2bda0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_145316-t6845jfr\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/t6845jfr\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 15.13it/s, Loss=18.8551]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:41<00:00,  4.88it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.198\n",
      "Forward: 41.03s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 23.22it/s, Loss=15.9725]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.14it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.079\n",
      "Forward: 38.94s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.72it/s, Loss=10.9732]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.23it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.345\n",
      "Forward: 38.27s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.93it/s, Loss=7.1314]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.14it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.383\n",
      "Forward: 38.92s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.14it/s, Loss=10.1655]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.19it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.656\n",
      "Forward: 38.55s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.52it/s, Loss=9.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.14it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.554\n",
      "Forward: 38.88s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.32it/s, Loss=11.5668]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.15it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.806\n",
      "Forward: 38.82s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.74it/s, Loss=8.5703]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.19it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.076\n",
      "Forward: 38.53s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.47it/s, Loss=13.2840]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.22it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.857\n",
      "Forward: 38.28s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.02it/s, Loss=10.2922]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.17it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.059\n",
      "Forward: 38.68s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.39it/s, Loss=8.0139]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.15it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.161\n",
      "Forward: 38.87s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.94it/s, Loss=9.8846]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:41<00:00,  4.86it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.074\n",
      "Forward: 41.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.16it/s, Loss=6.8100]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.18it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.184\n",
      "Forward: 38.63s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.64it/s, Loss=7.8704]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:40<00:00,  4.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.232\n",
      "Forward: 40.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.13it/s, Loss=5.3410]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.22it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.127\n",
      "Forward: 38.32s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.70it/s, Loss=8.4163]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:39<00:00,  5.04it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.247\n",
      "Forward: 39.72s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.92it/s, Loss=8.5193]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.22it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.227\n",
      "Forward: 38.32s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.43it/s, Loss=8.8938]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:38<00:00,  5.22it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.250\n",
      "Forward: 38.34s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.66it/s, Loss=9.1076]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:39<00:00,  5.08it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.249\n",
      "Forward: 39.35s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/t6845jfr\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_145316-t6845jfr/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_x4_custom \\\n",
    "    --ext sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39b31604",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/RFDN_SwinIR_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250528_141408-e1jo594x\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/e1jo594x\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.09s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 6.19s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/e1jo594x\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250528_141408-e1jo594x/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/RFDN_SwinIR_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save RFDN_SwinIR_x4_custom \\\n",
    "    --ext img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9e2013a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nV2(Î™®Îç∏Ïùò Ï¥àÎ∞ò Îã®Í≥ÑÏóê Swin TransformerÎ•º ÌÜµÌï¥ global contextÎ•º Í∞ïÏ°∞ÌïòÏó¨ Ïù¥ÌõÑÏùò RFDB Î∏îÎ°ùÎì§Ïù¥ Î≥¥Îã§ Î™ÖÌôïÌïòÍ≥† ÌíçÎ∂ÄÌïú ÌäπÏßïÏùÑ Ï∂îÏ∂úÌï† Ïàò ÏûàÍ≤å) Ïã§Ìñâ\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "V2(Î™®Îç∏Ïùò Ï¥àÎ∞ò Îã®Í≥ÑÏóê Swin TransformerÎ•º ÌÜµÌï¥ \n",
    "global contextÎ•º Í∞ïÏ°∞ÌïòÏó¨ Ïù¥ÌõÑÏùò RFDB Î∏îÎ°ùÎì§Ïù¥ Î≥¥Îã§ Î™ÖÌôïÌïòÍ≥† ÌíçÎ∂ÄÌïú ÌäπÏßïÏùÑ Ï∂îÏ∂úÌï† Ïàò ÏûàÍ≤å) Ïã§Ìñâ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa8a5eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250525_142152-5gdjg412\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/5gdjg412\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 17.77it/s, Loss=18.2157]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:23<00:00,  8.64it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.065\n",
      "Forward: 23.14s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.02it/s, Loss=11.7283]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.110\n",
      "Forward: 22.80s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 26.82it/s, Loss=8.2970]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.74it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.562\n",
      "Forward: 22.89s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.33it/s, Loss=9.4073]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.80it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.636\n",
      "Forward: 22.73s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.62it/s, Loss=12.9838]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.80it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.749\n",
      "Forward: 22.73s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 26.90it/s, Loss=10.4046]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.635\n",
      "Forward: 22.81s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.29it/s, Loss=7.7163]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.79it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.012\n",
      "Forward: 22.76s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.64it/s, Loss=9.4894]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.81it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.089\n",
      "Forward: 22.70s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.33it/s, Loss=8.2785]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:22<00:00,  8.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.114\n",
      "Forward: 22.82s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/5gdjg412\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250525_142152-5gdjg412/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR_v2 \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_v2_x4_custom \\\n",
    "    --ext sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b9c72ce0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_150858-5of1v1ht\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/5of1v1ht\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 17.95it/s, Loss=18.2155]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:31<00:00,  6.42it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.099\n",
      "Forward: 31.17s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.06it/s, Loss=11.6416]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.36it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.108\n",
      "Forward: 27.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 14.20it/s, Loss=7.6791]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.30it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.398\n",
      "Forward: 27.39s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.00it/s, Loss=9.4123]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.44it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.519\n",
      "Forward: 26.88s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.83it/s, Loss=14.6414]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.49it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.975\n",
      "Forward: 26.72s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.00it/s, Loss=10.3206]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.46it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.902\n",
      "Forward: 26.83s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.07it/s, Loss=7.6529]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.48it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.018\n",
      "Forward: 26.76s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.76it/s, Loss=9.6260]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.41it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.021\n",
      "Forward: 27.00s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.20it/s, Loss=8.3047]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.34it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.136\n",
      "Forward: 27.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.40it/s, Loss=10.8840]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.38it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.120\n",
      "Forward: 27.12s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.10it/s, Loss=11.2406]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.34it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.150\n",
      "Forward: 27.26s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.25it/s, Loss=9.8505]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.42it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.119\n",
      "Forward: 26.96s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.19it/s, Loss=8.2135]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.49it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.095\n",
      "Forward: 26.72s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.90it/s, Loss=9.8269]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.943\n",
      "Forward: 26.93s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.87it/s, Loss=8.0304]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.41it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.264\n",
      "Forward: 27.01s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.47it/s, Loss=8.1734]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:27<00:00,  7.40it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.256\n",
      "Forward: 27.02s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.96it/s, Loss=7.9777]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.47it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.144\n",
      "Forward: 26.77s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.92it/s, Loss=8.8025]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:28<00:00,  7.00it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.294\n",
      "Forward: 28.57s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 27.82it/s, Loss=9.8477]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:26<00:00,  7.42it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.265\n",
      "Forward: 26.96s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/5of1v1ht\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_150858-5of1v1ht/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR_v2 \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_v2_x4_custom \\\n",
    "    --ext sep\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "656b6b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/RFDN_SwinIR_v2_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250528_142043-x8e5w350\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/x8e5w350\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.78s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 5.59s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v2_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/x8e5w350\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250528_142043-x8e5w350/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR_v2 \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/RFDN_SwinIR_v2_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save RFDN_SwinIR_v2_x4_custom \\\n",
    "    --ext img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3d41cbec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransformer_sr Ïã§Ìñâ\\n->CNNÏùÑ Î™®Îì† pure TransformerÎ°ú replace Ìïú format\\n'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Transformer_sr Ïã§Ìñâ\n",
    "->CNNÏùÑ Î™®Îì† pure TransformerÎ°ú replace Ìïú format\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "178cc7c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250527_151313-wir1cfpq\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/wir1cfpq\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.29it/s, Loss=8.6513]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 36.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 5.41s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.58it/s, Loss=7.1625]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 34.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.199\n",
      "Forward: 5.81s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.18it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 38.11it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.201\n",
      "Forward: 5.25s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.87it/s, Loss=7.7905]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 38.18it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.203\n",
      "Forward: 5.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 33.56it/s, Loss=8.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.83it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.204\n",
      "Forward: 5.29s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.61it/s, Loss=12.2560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 34.07it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.205\n",
      "Forward: 5.87s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.58it/s, Loss=10.9011]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 35.25it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 5.67s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 33.56it/s, Loss=8.9522]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.65it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 5.31s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.99it/s, Loss=11.6089]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.92it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 5.28s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/wir1cfpq\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250527_151313-wir1cfpq/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save TransformerSR_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "55a227e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_152229-e5j7hogi\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/e5j7hogi\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.82it/s, Loss=8.6513]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 13.26it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 15.10s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.76it/s, Loss=7.1625]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.23it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.199\n",
      "Forward: 17.82s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 33.59it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.45it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.201\n",
      "Forward: 13.85s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.89it/s, Loss=7.7905]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.46it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.203\n",
      "Forward: 13.84s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.44it/s, Loss=8.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.70it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.204\n",
      "Forward: 14.60s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.56it/s, Loss=12.2560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.68it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.205\n",
      "Forward: 14.63s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.78it/s, Loss=10.9011]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.30it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 13.99s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.06it/s, Loss=8.9522]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.85it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 14.45s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.51it/s, Loss=11.6089]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:18<00:00, 10.90it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 18.36s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.74it/s, Loss=7.1719]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.81it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.210\n",
      "Forward: 13.51s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.85it/s, Loss=11.5601]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.45it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.211\n",
      "Forward: 13.86s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.01it/s, Loss=11.7415]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.44it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.212\n",
      "Forward: 17.49s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.16it/s, Loss=9.7036]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.86it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.214\n",
      "Forward: 14.43s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.47it/s, Loss=7.2746]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.33it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.216\n",
      "Forward: 13.96s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.69it/s, Loss=8.0981]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.35it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.218\n",
      "Forward: 15.00s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.90it/s, Loss=7.8555]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.67it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.219\n",
      "Forward: 14.64s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.33it/s, Loss=10.5071]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.16it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.222\n",
      "Forward: 14.14s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.35it/s, Loss=9.8017]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.67it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.223\n",
      "Forward: 13.65s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.30it/s, Loss=9.7298]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.71it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.225\n",
      "Forward: 17.08s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/e5j7hogi\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_152229-e5j7hogi/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save TransformerSR_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9a0ab7b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250531_123727-q7chb3vx\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/q7chb3vx\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.58it/s, Loss=8.6513]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:16<00:00, 12.36it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 16.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.78it/s, Loss=7.1625]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.72it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.199\n",
      "Forward: 14.59s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.89it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.60it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.201\n",
      "Forward: 14.71s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.49it/s, Loss=7.7905]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.88it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.203\n",
      "Forward: 14.41s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.63it/s, Loss=8.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.204\n",
      "Forward: 17.50s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.91it/s, Loss=12.2560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:16<00:00, 12.17it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.205\n",
      "Forward: 16.44s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.28it/s, Loss=10.9011]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.35it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 14.99s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.32it/s, Loss=8.9522]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.54it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 14.79s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/30:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.73it/s, Loss=11.6089]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 12.55it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 15.94s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.69it/s, Loss=7.1719]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 12.99it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.210\n",
      "Forward: 15.40s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.85it/s, Loss=11.5601]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.60it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.211\n",
      "Forward: 14.71s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.00it/s, Loss=11.7415]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.07it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.212\n",
      "Forward: 14.22s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.63it/s, Loss=9.7036]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.56it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.214\n",
      "Forward: 14.75s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.58it/s, Loss=7.2746]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.74it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.216\n",
      "Forward: 14.58s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.81it/s, Loss=8.0981]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.37it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.218\n",
      "Forward: 14.96s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.00it/s, Loss=7.8555]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.14it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.219\n",
      "Forward: 17.96s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.96it/s, Loss=10.5071]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.41it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.222\n",
      "Forward: 14.94s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.71it/s, Loss=9.8017]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.223\n",
      "Forward: 14.90s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.51it/s, Loss=9.7298]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.47it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.225\n",
      "Forward: 17.44s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 20]\tLearning rate: 1.00e-4\n",
      "Epoch 20/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 20/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.48it/s, Loss=7.2471]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.40it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.227\n",
      "Forward: 14.93s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 21]\tLearning rate: 1.00e-4\n",
      "Epoch 21/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 21/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.80it/s, Loss=7.9617]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.35it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.228\n",
      "Forward: 14.98s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 22]\tLearning rate: 1.00e-4\n",
      "Epoch 22/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 22/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.10it/s, Loss=10.1358]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.60it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.231\n",
      "Forward: 14.71s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 23]\tLearning rate: 1.00e-4\n",
      "Epoch 23/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.93it/s, Loss=8.5925]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.79it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.233\n",
      "Forward: 14.50s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 24]\tLearning rate: 1.00e-4\n",
      "Epoch 24/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 24/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.34it/s, Loss=7.1798]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.61it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.235\n",
      "Forward: 14.69s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 25]\tLearning rate: 1.00e-4\n",
      "Epoch 25/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 25/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.27it/s, Loss=9.0711]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.36it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.237\n",
      "Forward: 14.97s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 26]\tLearning rate: 1.00e-4\n",
      "Epoch 26/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 26/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 14.75it/s, Loss=11.3208]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.47it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.240\n",
      "Forward: 14.87s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 27]\tLearning rate: 1.00e-4\n",
      "Epoch 27/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 27/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.03it/s, Loss=9.4182]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 13.30it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.241\n",
      "Forward: 15.04s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 28]\tLearning rate: 1.00e-4\n",
      "Epoch 28/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 28/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.31it/s, Loss=9.8383]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 13.18it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.244\n",
      "Forward: 15.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 29]\tLearning rate: 1.00e-4\n",
      "Epoch 29/30:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 29/30: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 33.01it/s, Loss=7.8048]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.47it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.246\n",
      "Forward: 17.44s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/q7chb3vx\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250531_123727-q7chb3vx/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 30 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save TransformerSR_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b060fef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/TransformerSR_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250531_141244-6b9qoqhl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/6b9qoqhl\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.77s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 3.55s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/6b9qoqhl\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250531_141244-6b9qoqhl/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/TransformerSR_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save TransformerSR_x4_custom \\\n",
    "    --ext img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f4c77ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTransformer_ShiftedWindowAttention_sr\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Transformer_ShiftedWindowAttention_sr\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57da7509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250527_150033-itmoj9u1\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_ShiftedWindowAttention_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/itmoj9u1\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 22.33it/s, Loss=8.6513]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:07<00:00, 25.85it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 7.74s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.89it/s, Loss=7.1625]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 39.45it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.199\n",
      "Forward: 5.07s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.73it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.83it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.201\n",
      "Forward: 5.29s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.98it/s, Loss=7.7905]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 38.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.203\n",
      "Forward: 5.21s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 24.00it/s, Loss=8.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.03it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.204\n",
      "Forward: 5.40s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 34.36it/s, Loss=12.2560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.40it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.205\n",
      "Forward: 5.35s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.58it/s, Loss=10.9011]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.70it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 5.31s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.77it/s, Loss=8.9522]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 5.27s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 28.13it/s, Loss=11.6089]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:05<00:00, 37.74it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 5.30s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_ShiftedWindowAttention_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/itmoj9u1\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250527_150033-itmoj9u1/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr_shiftedattn \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save TransformerSR_ShiftedWindowAttention_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8b6ff687",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_154122-8q4s7z4p\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_ShiftedWindowAttention_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/8q4s7z4p\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 21.27it/s, Loss=8.6513]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.63it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 14.68s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.86it/s, Loss=7.1625]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.12it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.199\n",
      "Forward: 14.17s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.23it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.14it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.201\n",
      "Forward: 14.14s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.14it/s, Loss=7.7905]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.18it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.203\n",
      "Forward: 14.11s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.77it/s, Loss=8.9099]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.05it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.204\n",
      "Forward: 14.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.69it/s, Loss=12.2560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.74it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.205\n",
      "Forward: 14.56s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.39it/s, Loss=10.9011]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.57it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 13.74s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.13it/s, Loss=8.9522]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:16<00:00, 12.07it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 16.58s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.21it/s, Loss=11.6089]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.30it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.208\n",
      "Forward: 13.99s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.47it/s, Loss=7.1719]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:16<00:00, 12.49it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.210\n",
      "Forward: 16.02s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.27it/s, Loss=11.5601]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.89it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.211\n",
      "Forward: 13.44s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.81it/s, Loss=11.7415]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.08it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.212\n",
      "Forward: 14.21s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.38it/s, Loss=9.7036]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.40it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.214\n",
      "Forward: 13.90s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:02<00:00, 33.40it/s, Loss=7.2746]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.41it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.216\n",
      "Forward: 13.89s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 31.94it/s, Loss=8.0981]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.54it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.218\n",
      "Forward: 14.78s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.37it/s, Loss=7.8555]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 14.15it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.219\n",
      "Forward: 14.13s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.09it/s, Loss=10.5071]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:15<00:00, 12.78it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.222\n",
      "Forward: 15.66s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.23it/s, Loss=9.8017]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:13<00:00, 14.64it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.223\n",
      "Forward: 13.66s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:03<00:00, 32.20it/s, Loss=9.7298]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:14<00:00, 13.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.225\n",
      "Forward: 14.53s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_ShiftedWindowAttention_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/8q4s7z4p\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_154122-8q4s7z4p/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model transformer_sr_shiftedattn \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save TransformerSR_ShiftedWindowAttention_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f94efe79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMB_LGA Ïã§Ìñâ\\n'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "MB_LGA Ïã§Ìñâ\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f3f9ce09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250528_151247-zbgr7s9t\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mTransformerSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/zbgr7s9t\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [01:50<00:00,  1.10s/it, Loss=7.6995]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.88it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.213\n",
      "Forward: 51.55s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.14it/s, Loss=8.0815]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.226\n",
      "Forward: 50.29s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.27it/s, Loss=7.5302]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.99it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.249\n",
      "Forward: 50.12s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.02it/s, Loss=8.8504]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.91it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.307\n",
      "Forward: 51.21s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.37it/s, Loss=6.6398]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.351\n",
      "Forward: 50.48s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.01it/s, Loss=9.1302]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.90it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.367\n",
      "Forward: 51.35s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.15it/s, Loss=7.8752]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.399\n",
      "Forward: 50.50s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.91it/s, Loss=8.2131]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  4.00it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.438\n",
      "Forward: 50.05s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.21it/s, Loss=12.1698]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.95it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.491\n",
      "Forward: 50.62s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mTransformerSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/zbgr7s9t\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250528_151247-zbgr7s9t/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model MB_LGA \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save MB_LGA_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "61d1f93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_154913-4hf4w4wl\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMB_LGA_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/4hf4w4wl\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 14.23it/s, Loss=7.6994]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.86it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.213\n",
      "Forward: 51.77s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.95it/s, Loss=8.0813]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:52<00:00,  3.83it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.226\n",
      "Forward: 52.22s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.95it/s, Loss=7.5294]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.249\n",
      "Forward: 50.27s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.37it/s, Loss=8.8507]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.97it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.307\n",
      "Forward: 50.32s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.98it/s, Loss=6.6391]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:49<00:00,  4.01it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.349\n",
      "Forward: 49.92s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.00it/s, Loss=9.1286]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.97it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.368\n",
      "Forward: 50.43s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.56it/s, Loss=7.8756]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.94it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.398\n",
      "Forward: 50.72s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.33it/s, Loss=8.2142]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:49<00:00,  4.01it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.435\n",
      "Forward: 49.85s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.48it/s, Loss=12.1702]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:53<00:00,  3.76it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.487\n",
      "Forward: 53.21s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.94it/s, Loss=7.9405]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.91it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.528\n",
      "Forward: 51.20s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.03it/s, Loss=7.5985]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:53<00:00,  3.76it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.560\n",
      "Forward: 53.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.06it/s, Loss=10.8757]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:52<00:00,  3.80it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.586\n",
      "Forward: 52.60s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.32it/s, Loss=9.2652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.611\n",
      "Forward: 50.26s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.96it/s, Loss=5.8098]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.94it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.631\n",
      "Forward: 50.79s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.02it/s, Loss=5.6143]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.639\n",
      "Forward: 50.30s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.17it/s, Loss=9.2765]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.95it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.666\n",
      "Forward: 50.66s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.31it/s, Loss=7.9712]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.95it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.674\n",
      "Forward: 50.64s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.20it/s, Loss=7.0974]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:52<00:00,  3.83it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.708\n",
      "Forward: 52.18s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.72it/s, Loss=6.3975]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.716\n",
      "Forward: 50.47s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mMB_LGA_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/4hf4w4wl\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_154913-4hf4w4wl/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model MB_LGA \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save MB_LGA_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e416429",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250531_130111-24jmjf8v\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMB_LGA_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/24jmjf8v\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 5.00e-5\n",
      "Epoch 1/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:06<00:00,  7.46it/s, Loss=9.2277]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.90it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.198\n",
      "Forward: 51.26s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 5.00e-5\n",
      "Epoch 2/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.56it/s, Loss=9.8418]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:53<00:00,  3.77it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.206\n",
      "Forward: 53.03s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 5.00e-5\n",
      "Epoch 3/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.62it/s, Loss=7.7825]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.93it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.212\n",
      "Forward: 50.93s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 5.00e-5\n",
      "Epoch 4/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.41it/s, Loss=6.2554]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:49<00:00,  4.01it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.216\n",
      "Forward: 49.90s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 5.00e-5\n",
      "Epoch 5/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.61it/s, Loss=10.6190]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.94it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.220\n",
      "Forward: 50.74s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 5.00e-5\n",
      "Epoch 6/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.52it/s, Loss=8.4287]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.92it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.226\n",
      "Forward: 51.03s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 5.00e-5\n",
      "Epoch 7/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.54it/s, Loss=9.6359]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.231\n",
      "Forward: 50.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 5.00e-5\n",
      "Epoch 8/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.56it/s, Loss=10.8543]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.238\n",
      "Forward: 50.53s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 5.00e-5\n",
      "Epoch 9/20:   0%|                                        | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.57it/s, Loss=9.0673]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.85it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.246\n",
      "Forward: 51.90s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 5.00e-5\n",
      "Epoch 10/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.64it/s, Loss=7.5367]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.87it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.260\n",
      "Forward: 51.73s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 5.00e-5\n",
      "Epoch 11/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.53it/s, Loss=9.6221]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.277\n",
      "Forward: 50.45s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 5.00e-5\n",
      "Epoch 12/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.53it/s, Loss=7.2229]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.99it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.298\n",
      "Forward: 50.14s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 5.00e-5\n",
      "Epoch 13/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.60it/s, Loss=8.0701]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.93it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.311\n",
      "Forward: 50.85s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 5.00e-5\n",
      "Epoch 14/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.39it/s, Loss=7.9992]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.90it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.323\n",
      "Forward: 51.29s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 5.00e-5\n",
      "Epoch 15/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.55it/s, Loss=7.9652]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.330\n",
      "Forward: 50.46s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 5.00e-5\n",
      "Epoch 16/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.39it/s, Loss=8.8725]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.98it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.344\n",
      "Forward: 50.23s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 5.00e-5\n",
      "Epoch 17/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.48it/s, Loss=7.9086]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:50<00:00,  3.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.350\n",
      "Forward: 50.51s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 5.00e-5\n",
      "Epoch 18/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.50it/s, Loss=6.1923]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.91it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.362\n",
      "Forward: 51.16s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 5.00e-5\n",
      "Epoch 19/20:   0%|                                       | 0/50 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 50/50 [00:04<00:00, 10.58it/s, Loss=6.5662]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:51<00:00,  3.90it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.366\n",
      "Forward: 51.26s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mMB_LGA_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/24jmjf8v\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250531_130111-24jmjf8v/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model MB_LGA \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 32 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 5e-5 \\\n",
    "    --save MB_LGA_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "58a33766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/MB_LGA_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250531_141825-ed00lh8l\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mMB_LGA_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/ed00lh8l\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.83s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 5.68s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mMB_LGA_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/ed00lh8l\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250531_141825-ed00lh8l/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model MB_LGA \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/MB_LGA_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save MB_LGA_x4_custom \\\n",
    "    --ext img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c579eb0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nRFDN_SwinIR_v3\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "RFDN_SwinIR_v3\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2711404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250529_152405-2ipme4dt\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/2ipme4dt\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 12.78it/s, Loss=23.0237]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.38it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.186\n",
      "Forward: 45.70s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.22it/s, Loss=12.4992]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.51it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.481\n",
      "Forward: 44.31s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.30it/s, Loss=10.3678]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.53it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.281\n",
      "Forward: 44.17s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.25it/s, Loss=10.3676]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.52it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.539\n",
      "Forward: 44.26s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.89it/s, Loss=9.7231]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.44it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.763\n",
      "Forward: 45.03s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.52it/s, Loss=12.3081]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:47<00:00,  4.20it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.770\n",
      "Forward: 47.59s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.06it/s, Loss=7.8711]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.51it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.965\n",
      "Forward: 44.34s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.36it/s, Loss=9.7430]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:43<00:00,  4.55it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.054\n",
      "Forward: 43.91s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/10:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/10: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.96it/s, Loss=9.7060]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:47<00:00,  4.25it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.078\n",
      "Forward: 47.07s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/2ipme4dt\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250529_152405-2ipme4dt/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR_v3 \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 10 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_v3_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a282d57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250530_160813-yddbfex2\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/yddbfex2\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:06<00:00, 14.39it/s, Loss=23.0247]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.38it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.186\n",
      "Forward: 45.71s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.10it/s, Loss=12.3404]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.46it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.796\n",
      "Forward: 44.84s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.06it/s, Loss=10.2819]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.49it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.307\n",
      "Forward: 44.59s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.09it/s, Loss=10.2929]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.48it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.581\n",
      "Forward: 44.66s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.46it/s, Loss=9.6815]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.38it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.465\n",
      "Forward: 45.62s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.19it/s, Loss=12.0373]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.50it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.735\n",
      "Forward: 44.44s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.59it/s, Loss=8.5521]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.50it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.976\n",
      "Forward: 44.48s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.69it/s, Loss=10.3561]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.54it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.055\n",
      "Forward: 44.03s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.72it/s, Loss=9.4559]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.36it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.083\n",
      "Forward: 45.89s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.21it/s, Loss=8.0294]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.54it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.076\n",
      "Forward: 44.10s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.29it/s, Loss=8.1927]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.52it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.172\n",
      "Forward: 44.24s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.05it/s, Loss=9.2822]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.47it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.145\n",
      "Forward: 44.77s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.49it/s, Loss=6.3492]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.49it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.214\n",
      "Forward: 44.54s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.47it/s, Loss=8.6471]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.155\n",
      "Forward: 45.19s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.89it/s, Loss=7.1413]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.43it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.193\n",
      "Forward: 45.16s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.63it/s, Loss=10.3592]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.53it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.024\n",
      "Forward: 44.19s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.95it/s, Loss=9.3356]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:44<00:00,  4.54it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.281\n",
      "Forward: 44.05s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.16it/s, Loss=6.6684]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:43<00:00,  4.56it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.283\n",
      "Forward: 43.84s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.72it/s, Loss=7.8774]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:45<00:00,  4.35it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 26.283\n",
      "Forward: 46.00s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/yddbfex2\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250530_160813-yddbfex2/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model RFDN_SwinIR_v3 \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --save RFDN_SwinIR_v3_x4_custom \\\n",
    "    --ext sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc1a113a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/RFDN_SwinIR_v3_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250531_140956-48kuemma\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/48kuemma\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:06<00:00,  3.08s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 6.18s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mRFDN_SwinIR_v3_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/48kuemma\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250531_140956-48kuemma/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model rfdn_swinir_v3 \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/RFDN_SwinIR_v3_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save RFDN_SwinIR_v3_x4_custom \\\n",
    "    --ext img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dd8c8332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torchinfo\n",
      "  Downloading torchinfo-1.8.0-py3-none-any.whl.metadata (21 kB)\n",
      "Downloading torchinfo-1.8.0-py3-none-any.whl (23 kB)\n",
      "Installing collected packages: torchinfo\n",
      "Successfully installed torchinfo-1.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "774ec092",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content        demo.py\t    loss     option.py\t  trainer.py\t  wandb\r\n",
      "data\t       demo.sh\t    main.py  __pycache__  utility.py\r\n",
      "dataloader.py  __init__.py  model    template.py  videotester.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "17f228a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_LGA parameters: 1,004,035\n",
      "Swin_IR parameters: 1,124,913\n",
      "Swin_IR_v3 parameters: 1,161,435\n",
      "Transformer_SR parameters: 765,440\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.mb_lga import make_model as make_MB_LGA\n",
    "from model.rfdn_swinir import make_model as make_RFDN_SwinIR\n",
    "from model.rfdn_swinir_v3 import make_model as make_RFDN_SwinIR_v3\n",
    "from model.transformer_sr import make_model as make_Transformer_SR\n",
    "\n",
    "# Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "class Args:\n",
    "    scale = [4]\n",
    "    n_colors = 3\n",
    "    n_feats = 64\n",
    "\n",
    "args = Args()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Î™®Îç∏ Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
    "model_mb_lga = make_MB_LGA(args)\n",
    "model_swinir = make_RFDN_SwinIR(args)\n",
    "model_swinir_v3 = make_RFDN_SwinIR_v3(args)\n",
    "model_transformer_sr = make_Transformer_SR(args)\n",
    "\n",
    "# ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò Ï∂úÎ†•\n",
    "print(f'MB_LGA parameters: {count_parameters(model_mb_lga):,}')\n",
    "print(f'Swin_IR parameters: {count_parameters(model_swinir):,}')\n",
    "print(f'Swin_IR_v3 parameters: {count_parameters(model_swinir_v3):,}')\n",
    "print(f'Transformer_SR parameters: {count_parameters(model_transformer_sr):,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "01321ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MB_LGA parameters: 1,004,035\n",
      "Swin_IR parameters: 1,124,913\n",
      "Swin_IR_v3 parameters: 1,161,435\n",
      "Transformer_SR parameters: 765,440\n",
      "RFDN parameters: 433,448\n",
      "Fusion_SR parameters: 5,750\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from model.mb_lga import make_model as make_MB_LGA\n",
    "from model.rfdn_swinir import make_model as make_RFDN_SwinIR\n",
    "from model.rfdn_swinir_v3 import make_model as make_RFDN_SwinIR_v3\n",
    "from model.transformer_sr import make_model as make_Transformer_SR\n",
    "from model.rfdn import make_model as make_RFDN\n",
    "from model.fusion_sr import make_model as make_Fusion\n",
    "\n",
    "# Î™®Îç∏ ÌååÎùºÎØ∏ÌÑ∞ ÏÑ§Ï†ï\n",
    "class Args:\n",
    "    scale = [4]\n",
    "    n_colors = 3\n",
    "    n_feats = 64\n",
    "    rfdn_ckpt ='../experiment/RFDN_x4_custom/model/model_best.pt'\n",
    "    transformerSR_ckpt ='../experiment/TransformerSR_x4_custom/model/model_best.pt'\n",
    "    fusion_ch = 50\n",
    "\n",
    "args = Args()\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "# Î™®Îç∏ Ïù∏Ïä§ÌÑ¥Ïä§ ÏÉùÏÑ±\n",
    "model_mb_lga = make_MB_LGA(args)\n",
    "model_swinir = make_RFDN_SwinIR(args)\n",
    "model_swinir_v3 = make_RFDN_SwinIR_v3(args)\n",
    "model_transformer_sr = make_Transformer_SR(args)\n",
    "model_rfdn = make_RFDN(args)\n",
    "model_fusion_sr = make_Fusion(args)\n",
    "\n",
    "# ÌååÎùºÎØ∏ÌÑ∞ Í∞úÏàò Ï∂úÎ†•\n",
    "print(f'MB_LGA parameters: {count_parameters(model_mb_lga):,}')\n",
    "print(f'Swin_IR parameters: {count_parameters(model_swinir):,}')\n",
    "print(f'Swin_IR_v3 parameters: {count_parameters(model_swinir_v3):,}')\n",
    "print(f'Transformer_SR parameters: {count_parameters(model_transformer_sr):,}')\n",
    "print(f'RFDN parameters: {count_parameters(model_rfdn):,}')\n",
    "print(f'Fusion_SR parameters: {count_parameters(model_fusion_sr):,}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "046cd5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FusionSR  total: 1,204,638  |  trainable: 5,750\n"
     ]
    }
   ],
   "source": [
    "def count_params(model):\n",
    "    total = sum(p.numel() for p in model.parameters())\n",
    "    train = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    return total, train\n",
    "\n",
    "total, train = count_params(model_fusion_sr)\n",
    "print(f'FusionSR  total: {total:,}  |  trainable: {train:,}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2811624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nFusion_SR\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Fusion_SR\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2121b76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Preparing loss function:\n",
      "1.000 * L1\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250613_113114-gf4cggos\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mFusionSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/gf4cggos\u001b[0m\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 1]\tLearning rate: 1.00e-4\n",
      "Epoch 1/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 1/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:07<00:00, 14.11it/s, Loss=21.3430]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:20<00:00,  9.76it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 19.885\n",
      "Forward: 20.49s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 2]\tLearning rate: 1.00e-4\n",
      "Epoch 2/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 2/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.36it/s, Loss=15.7918]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.35it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 22.559\n",
      "Forward: 17.62s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 3]\tLearning rate: 1.00e-4\n",
      "Epoch 3/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 3/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.46it/s, Loss=13.7706]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.46it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 23.441\n",
      "Forward: 17.46s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 4]\tLearning rate: 1.00e-4\n",
      "Epoch 4/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 4/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.68it/s, Loss=15.5623]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.13it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.040\n",
      "Forward: 18.00s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 5]\tLearning rate: 1.00e-4\n",
      "Epoch 5/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 5/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.58it/s, Loss=17.0530]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:18<00:00, 11.07it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.385\n",
      "Forward: 18.07s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 6]\tLearning rate: 1.00e-4\n",
      "Epoch 6/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 6/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.25it/s, Loss=11.9582]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.53it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.712\n",
      "Forward: 17.35s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 7]\tLearning rate: 1.00e-4\n",
      "Epoch 7/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.56it/s, Loss=8.7848]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:18<00:00, 10.96it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.156\n",
      "Forward: 18.26s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 8]\tLearning rate: 1.00e-4\n",
      "Epoch 8/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 8/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.44it/s, Loss=9.7560]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.16it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.032\n",
      "Forward: 17.93s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 9]\tLearning rate: 1.00e-4\n",
      "Epoch 9/20:   0%|                                       | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 9/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.28it/s, Loss=8.4567]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.28it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 24.911\n",
      "Forward: 17.74s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 10]\tLearning rate: 1.00e-4\n",
      "Epoch 10/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 10/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.84it/s, Loss=9.2081]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.18it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.279\n",
      "Forward: 17.91s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 11]\tLearning rate: 1.00e-4\n",
      "Epoch 11/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 11/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:04<00:00, 20.17it/s, Loss=10.0896]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.26it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.376\n",
      "Forward: 17.77s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 12]\tLearning rate: 1.00e-4\n",
      "Epoch 12/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 12/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.89it/s, Loss=11.7371]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.40it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.311\n",
      "Forward: 17.56s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 13]\tLearning rate: 1.00e-4\n",
      "Epoch 13/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 13/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.56it/s, Loss=9.1334]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.25it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.246\n",
      "Forward: 17.79s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 14]\tLearning rate: 1.00e-4\n",
      "Epoch 14/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 14/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 18.97it/s, Loss=8.7305]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.67it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.352\n",
      "Forward: 17.14s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 15]\tLearning rate: 1.00e-4\n",
      "Epoch 15/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.43it/s, Loss=10.9804]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.20it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.235\n",
      "Forward: 17.86s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 16]\tLearning rate: 1.00e-4\n",
      "Epoch 16/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 16/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.29it/s, Loss=8.3137]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.12it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.583\n",
      "Forward: 18.01s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 17]\tLearning rate: 1.00e-4\n",
      "Epoch 17/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 17/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.95it/s, Loss=9.3782]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.17it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.576\n",
      "Forward: 17.91s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 18]\tLearning rate: 1.00e-4\n",
      "Epoch 18/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 18/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.69it/s, Loss=8.4831]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.23it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.565\n",
      "Forward: 17.81s\n",
      "\n",
      "/home/elicer/.local/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:437: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "[Epoch 19]\tLearning rate: 1.00e-4\n",
      "Epoch 19/20:   0%|                                      | 0/100 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Epoch 19/20: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 100/100 [00:05<00:00, 19.94it/s, Loss=9.5351]\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: DIV2KCustom: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 200/200 [00:17<00:00, 11.19it/s]\n",
      "[DIV2KCustom x4]\tPSNR: 25.589\n",
      "Forward: 17.87s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mFusionSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/gf4cggos\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250613_113114-gf4cggos/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model fusion_sr \\\n",
    "    --data_train DIV2KCustom \\\n",
    "    --data_test DIV2KCustom \\\n",
    "    --dir_data /home/elicer/content/data \\\n",
    "    --scale 4 \\\n",
    "    --patch_size 96 \\\n",
    "    --batch_size 16 \\\n",
    "    --epochs 20 \\\n",
    "    --lr 1e-4 \\\n",
    "    --fusion_ch 50\\\n",
    "    --save FusionSR_x4_custom \\\n",
    "    --ext sep "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "12127a30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Making model...\n",
      "Load the model from ../experiment/FusionSR_x4_custom/model/model_best.pt\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvecum0814\u001b[0m (\u001b[33mvecum0814-korea-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Tracking run with wandb version 0.19.11\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run data is saved locally in \u001b[35m\u001b[1m/home/elicer/EDSR-PyTorch/src/wandb/run-20250614_031636-ndof12hj\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Run \u001b[1m`wandb offline`\u001b[0m to turn off syncing.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Syncing run \u001b[33mFusionSR_x4_custom\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: ‚≠êÔ∏è View project at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution\u001b[0m\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: üöÄ View run at \u001b[34m\u001b[4mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/ndof12hj\u001b[0m\n",
      "\n",
      "Evaluation:\n",
      "Test Dataset: Demo:   0%|                                 | 0/2 [00:00<?, ?it/s]/home/elicer/.local/lib/python3.10/site-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 6 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "Test Dataset: Demo: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:05<00:00,  2.85s/it]\n",
      "[Demo x4]\tPSNR: 0.000\n",
      "Forward: 5.71s\n",
      "\n",
      "\u001b[1;34mwandb\u001b[0m: \n",
      "\u001b[1;34mwandb\u001b[0m: üöÄ View run \u001b[33mFusionSR_x4_custom\u001b[0m at: \u001b[34mhttps://wandb.ai/vecum0814-korea-university/RFDN-SuperResolution/runs/ndof12hj\u001b[0m\n",
      "\u001b[1;34mwandb\u001b[0m: Find logs at: \u001b[1;35mwandb/run-20250614_031636-ndof12hj/logs\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!python main.py \\\n",
    "    --model fusion_sr \\\n",
    "    --data_test Demo \\\n",
    "    --dir_data /home/elicer/content/single_test \\\n",
    "    --scale 4 \\\n",
    "    --pre_train ../experiment/FusionSR_x4_custom/model/model_best.pt \\\n",
    "    --test_only \\\n",
    "    --save_results \\\n",
    "    --save FusionSR_x4_custom \\\n",
    "    --fusion_ch 50\\\n",
    "    --ext img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622808fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
